Short answer: if by “understand” you mean forming internal models that support accurate prediction, control, or proof, then modern AI systems can grasp kinds of structure that humans, unaided, essentially can’t. If you mean having a human‑like, explainable, intuitive grasp, then the story is murkier—AIs often get the right answers for reasons that don’t translate into human concepts.